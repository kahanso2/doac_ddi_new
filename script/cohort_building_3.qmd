---
title: "cohort_building_2"
author: "Kent Hanson"
format: html
editor: visual
---

#To Do

Talked to Todd - we are going to expand inclusion criteria so that so long as \>183 days without OAC use and 18+ at index then we will allow in study. That means, if someone had OAC use (but no event) on 1/1/2000 and then had a 1 year gap, started OAC, and had event, then they are in the study. We will only take the first instance of this for a person so they cannot contribute multiple times to the analysis.

Look at resources folder for papers used to support this work \# About

The goal of this analysis is to explore DDI in CVD using the SCCS as a high-throughput screening technique

SHOULD BE FINAL. RUN THIS BITCH (actually have to loop drugs still)

# Packages

```{r}
#| label: load-packages/functions
#| include: false

proj_root <- "C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new"

pacman::p_load(tidyverse, arrow, duckdb, tictoc, haven, reshape2, lubridate, SCCS, janitor, fs, here, AdhereR, remotes, lme4, gnm, survival, grid, forestploter, duckplyr,  data.table, progress, readxl, zoo, msm, httr, jsonlite, gt, dbplyr)

# Call functions
source(here("codes/functions.R"))
source(here("codes/codes.R"))

# Load + split into raw vs. clean NDC11-only
redbook_raw <- open_dataset("//pharm-c-psop/TruvenData/Truven Data R/redbook.parquet") |>
  mutate(NDCNUM = as.character(NDCNUM)) |>
  collect()

redbook <- redbook_raw |>
  mutate(ndc11_ok = grepl("^[0-9]{11}$", NDCNUM)) |>
  filter(ndc11_ok) |>
  select(-ndc11_ok)

options(scipen = 999)

oac_drug_list <- c("Warf", "Apix", "Rivarox", "Dabig", "Edoxa")

# Base case:
USE_GRACE_OBJECT  <- TRUE
USE_GRACE_PRECIP  <- TRUE
INCLUDE_WASHOUT   <- FALSE
ADJUST_30DAY      <- TRUE

# Sensitivity # 1:
# USE_GRACE_OBJECT  <- FALSE
# USE_GRACE_PRECIP  <- FALSE
# INCLUDE_WASHOUT   <- TRUE
```

# Clean Drug Data File by Updating Blank NDCs

```{r}

# Read distinct NDC numbers from CCAE & MDCR datasets then bind
all_ccae_ndc <- open_dataset("//pharm-c-psop/TruvenData/Truven Data R/ccae/d") |> 
  select(NDCNUM) |> 
  distinct(NDCNUM) |> 
  collect()

all_mdcr_ndc <- open_dataset("//pharm-c-psop/TruvenData/Truven Data R/mdcr/d") |> 
  select(NDCNUM) |> 
  distinct(NDCNUM) |> 
  collect()

full_ndc <- bind_rows(all_ccae_ndc, all_mdcr_ndc) |> 
  distinct(NDCNUM) |> 
  filter(!is.na(NDCNUM)) |>
  filter(grepl("^[0-9]{11}$", NDCNUM)) |>   # keep only plausible 11-digit, digits-only NDCs
  distinct(NDCNUM)


# Join the NDC numbers to Redbook and identify NDC with no GENNME
id_blank_GENNME <- full_ndc |> 
  left_join(redbook, by = "NDCNUM") |> 
  select(NDCNUM, GENNME, MSTFMDS, MASTFRM, ROADS, DEACLDS, THRDTDS, THERCLS) |> 
  filter(is.na(GENNME)) |> 
  distinct(NDCNUM, .keep_all = TRUE)


# Define a function to get the generic name for an NDC codefrom RxNorm API

# lightweight memoized cache so repeated NDCs aren’t re-fetched
.ndc_cache <- new.env(parent = emptyenv())

get_generic_name <- function(ndc) {
  if (is.na(ndc) || ndc == "" || is.null(ndc)) return(NA_character_)
  if (exists(ndc, envir = .ndc_cache, inherits = FALSE))
    return(get(ndc, envir = .ndc_cache, inherits = FALSE))
  
  url <- paste0("https://rxnav.nlm.nih.gov/REST/ndcstatus.json?ndc=", ndc)
  
   for (attempt in 1:2) {
    resp <- try(httr::GET(url, httr::timeout(10)), silent = TRUE)
    if (!inherits(resp, "try-error") && httr::status_code(resp) == 200) {
      txt <- try(httr::content(resp, "text", encoding = "UTF-8"), silent = TRUE)
      if (!inherits(txt, "try-error") && !is.null(txt)) {
        dat <- try(jsonlite::fromJSON(txt), silent = TRUE)
        if (!inherits(dat, "try-error")) {
          val <- dat$ndcStatus$conceptName
          out <- if (is.null(val) || length(val) == 0) NA_character_ else as.character(val[1])
          assign(ndc, out, envir = .ndc_cache)
          return(out)
        }
      }
    }
    # brief backoff on first failure
    if (attempt == 1) Sys.sleep(0.3)
  }

  assign(ndc, NA_character_, envir = .ndc_cache)
  NA_character_
}

# Uncomment the lines below to test the function: 
# example_ndc <- "67544009794"  # Replace with NDC code
# generic_name <- get_generic_name(example_ndc)
# print(paste("NDC:", example_ndc, "- Generic Name:", generic_name))

# Retrieve Missing Generic Names and Add Route Information

# Retrieve generic names for NDCs with missing GENNME from redbook & convert to title case
id_blank_GENNME$generic_name <- vapply(id_blank_GENNME$NDCNUM, get_generic_name, FUN.VALUE = NA_character_) |> 
  str_to_title()

# Add a 'route' column based on keywords in the generic name
id_blank_GENNME_added <- id_blank_GENNME |> 
  mutate(
    route = case_when(
      str_detect(generic_name, "Oral|Tablet|Capsule|Chewable") ~ "Oral",
      str_detect(generic_name, "Topical|Lotion|Cream") ~ "Topical application",
      str_detect(generic_name, "Injectable|Prefilled Syringe|Injection") ~ "Injectable",
      str_detect(generic_name, "Transdermal") ~ "Transdermal",
      str_detect(generic_name, "Ophthalmic") ~ "Ophthalmic",
      str_detect(generic_name, "Otic") ~ "Otic",
      TRUE ~ NA_character_  # Default to NA if no conditions are met
    ) 
  ) |> 
  transmute(NDCNUM, generic_name = as.character(generic_name), route)

# Filter the cleaned dataset for rows where the generic name matches one of the OAC drugs
blank_oac_ndc <- id_blank_GENNME_added |> 
  mutate(oac_flag = str_detect(generic_name, regex(str_c(oac_drug_list, collapse = "|"), ignore_case = TRUE))) |>
  filter(oac_flag) |> # only includes warfarin rx
  pull(NDCNUM) 

# Function to pull drug ndc for relevant drugs from redbook by matching generic names
get_ndc_by_drug_name <- function(drug_list, extra_ndcs) {
  redbook_ndcs <- redbook |> 
    filter(str_detect(GENNME, regex(str_c(drug_list, collapse = "|"), ignore_case = TRUE))) |> 
    distinct(NDCNUM) |> 
    pull()
  
  # Combine redbook NDCs with those from blank_oac_ndc vector above
  all_ndcs <- unique(c(as.character(redbook_ndcs), as.character(extra_ndcs)))
  
  all_ndcs[grepl("^[0-9]{11}$", all_ndcs)] # limits to ndcs 11 digits long composed of numbers only

}

# Get the unified OAC NDC vector
oac_ndc <- get_ndc_by_drug_name(oac_drug_list, blank_oac_ndc)

```

# Drug Data

```{r}

# Use extract_drug_name_data function to pull data for oac cohort (i.e., full oac drug use)

ccaed_oac_2009_2021 <- extract_drug_name_data(
  dataset_path = "//pharm-c-psop/TruvenData/Truven Data R/ccae/d", 
  output_path = file.path(proj_root, "data", "ccaed_oac_2009_2021.parquet"), 
  enrolid_filter = NULL,
  ndc_filter = oac_ndc
)

mdcrd_oac_2009_2021 <- extract_drug_name_data(
  dataset_path = "//pharm-c-psop/TruvenData/Truven Data R/mdcr/d", 
  output_path = file.path(proj_root, "data", "mdcrd_oac_2009_2021.parquet"), 
  enrolid_filter = NULL,
  ndc_filter = oac_ndc)

# Bind drug files from CCAE and MDCR
all_drug_oac <- bind_rows(ccaed_oac_2009_2021, mdcrd_oac_2009_2021) # 29,015,802 observations


# Merge in blank drug names from above
all_drug_oac_2009_2021 <- all_drug_oac |>
  filter(!is.na(ENROLID)) |>
  left_join(id_blank_GENNME_added, by = "NDCNUM") |>
  mutate(GENNME = if_else(is.na(GENNME), generic_name, GENNME)) |>
  select(-generic_name) |>
  mutate(GENNME = canon_drug(GENNME))


# Save dataset so don't have to do that again
all_drug_oac_2009_2021 |> write_parquet(file.path(proj_root, "data", "all_drug_oac_2009_2021.parquet"))

#### CODE TO OPEN DATASET WITHOUT RUNNING ABOVE ####

# Open dataset
# all_drug_oac_2009_2021 <- read_parquet(file.path(proj_root, "data", "all_drug_oac_2009_2021.parquet"))

# Save unique IDs of oac users
all_oac_users <- unique(all_drug_oac_2009_2021$ENROLID) # 2,618,363 users

```

#Clean drug data

```{r}
# # ── OLD: Apply data cleaning functions to OAC drug dataset ───────────────────────────
# cleaned_drug_data <- all_drug_2009_2021 |> 
#   clean_canceling_claims() |> 
#   remove_sequential_pairs() |> 
#   select_max_fill() # 27,419,333 observations

# NEW Function
# ===========================
# Drug-data cleaning (pairwise cancels + nearest future − within 15 days)
# ===========================
# 1) SAME-DAY cancels: remove +x/−x in PAIRS within (ENROLID, GENNME, SVCDATE, |DAYSUPP|).
#    If there are extra unmatched fills (e.g., +10,+10 and −10), keep the leftover (+10).
# 2) SEQUENTIAL cancels: for each positive +x, find the NEAREST future negative −x within 15 days.
#    Match each negative at most once; drop both sides of each matched pair.
# 3) Max-per-day: among remaining fills on the same day, keep the row with the largest DAYSUPP.
#
# ===========================

clean_drug_data_dt <- function(df) {
  # ---- 0) Convert to data.table and use efficient types ----
  dt <- as.data.table(df)[
    , .(
      ENROLID,
      GENNME,
      SVCDATE = as.IDate(SVCDATE),   # IDate = integer-backed Date → cheap joins/arithmetic
      DAYSUPP = as.integer(DAYSUPP), # int is smaller/faster than double for day counts
      AGE,
      NDCNUM
    )
  ]

  # Optional: use all CPU threads for speed
  setDTthreads(percent = 100)

  # Stable row id so we can drop exact rows later
  dt[, id := .I]

  # Precompute helpers once (avoid recomputing in filters)
  dt[, amt  := abs(DAYSUPP)]                                      # |days supply|
  dt[, sign := fifelse(DAYSUPP > 0L, 1L, fifelse(DAYSUPP < 0L, -1L, 0L))]  # +1 / -1 / 0

  # ---- 1) SAME-DAY PAIRWISE cancels (+x with −x on the same day and same |amt|) ----
  # Group is (person, drug, service date, |days|)
  dt[, n_pos := sum(sign == 1L),  by = .(ENROLID, GENNME, SVCDATE, amt)]   # how many + in group
  dt[, n_neg := sum(sign == -1L), by = .(ENROLID, GENNME, SVCDATE, amt)]   # how many − in group

  # Row number WITHIN each (group × sign) so we can remove only min(n_pos, n_neg) rows from both sides
  dt[, k := rowid(ENROLID, GENNME, SVCDATE, amt, sign)]

  # Mark rows to drop if they are within the first min(n_pos, n_neg) of their sign (pairwise removal)
  dt[, to_drop_same_day := (sign != 0L) & (k <= pmin(n_pos, n_neg))]

  # Keep everything NOT marked for same-day pairwise drop (explicit boolean in i avoids the single-symbol gotcha)
  dt1 <- dt[to_drop_same_day == FALSE,
            .(id, ENROLID, GENNME, SVCDATE, DAYSUPP, AGE, NDCNUM, amt, sign)]

  # ---- 2) SEQUENTIAL cancels within 15 days (nearest future −x; each − used once) ----
  # Split into positives and negatives with minimal columns for the join
  pos <- dt1[sign == 1L, .(id, ENROLID, GENNME, amt, SVCDATE)]
  neg <- dt1[sign == -1L, .(id, ENROLID, GENNME, amt, SVCDATE)]

  # Build intervals: positives search window is [date, date+15]; negatives are point events [date, date]
  pos[, `:=`(start = SVCDATE, end = SVCDATE + 15L)]
  neg[, `:=`(start = SVCDATE, end = SVCDATE)]

  # Keys (sorted indexes) speed up the interval join
  setkey(pos, ENROLID, GENNME, amt, start, end)
  setkey(neg, ENROLID, GENNME, amt, start, end)

  # Interval overlap join: match − rows that fall inside each + row’s [date, date+15] window
  ov <- foverlaps(pos, neg, nomatch = 0L)

  # Keep only future/same-day negatives (exclude past cancels)
  # (In overlap result, columns from 'pos' get 'i.' prefix; 'start' is from neg here.)
  ov <- ov[(i.start - start) >= 0L]

  # For each positive id, choose the nearest negative (earliest ndate)
  setorder(ov, id, i.SVCDATE)         # 'id' is pos id; 'i.SVCDATE' is neg date
  ov1 <- ov[!duplicated(id)]          # keep first match per positive

  # Ensure each negative is used at most once (greedy: earliest pos wins)
  setorder(ov1, i.id, SVCDATE)        # 'i.id' is neg id; 'SVCDATE' is pos date
  pairs <- ov1[!duplicated(i.id)]

  # Drop BOTH sides of each matched pair
  drop_ids <- c(pairs$id, pairs$i.id)
  dt2 <- dt1[!id %in% drop_ids]

  # ---- 3) If multiple fills remain on same day, keep max DAYSUPP ----
  # Also remove any leftover negatives just in case (should be rare at this point)
  cleaned <- dt2[DAYSUPP >= 0L][
    order(ENROLID, GENNME, SVCDATE, -DAYSUPP, id)   # put max DAYSUPP first per day
  ][
    , .SD[1L], by = .(ENROLID, GENNME, SVCDATE)     # take first row per group (= max)
  ][
    , .(ENROLID, GENNME, SVCDATE, DAYSUPP, AGE)          # final columns (drop NDCNUM per your original)
  ]

  cleaned
}

cleaned_drug_data <- clean_drug_data_dt(all_drug_oac_2009_2021)

# ── Save dataset so we don't have to redo ───────────────────────────────────────
write_parquet(cleaned_drug_data, file.path(proj_root, "data", "cleaned_drug_data.parquet"))

# ── (Optional) Open dataset later without rerunning cleaning ────────────────────
# cleaned_drug_data <- read_parquet("file.path(proj_root, "data", "control", "cleaned_drug_data.parquet"))

```

# Assign Index Date

```{r}
# 
# #Apply functions to create index dates and age-eligible population - OLD
# all_oac_index <- cleaned_drug_data |> 
#   arrange(ENROLID, SVCDATE) |> 
#  # collect() |> 
#   calculate_drug_end_plus_grace(adherence_multiplier = 0.3, cap = 30) |> 
#   flag_gaps_and_assign_episodes(gap_allowed = 183) |> 
#   assign_index_date_and_med() |> 
#   filter_new_users_age(earliest_index_date = '2009-07-02', age_criteria = 18)

# NEW Function
postclean_assign_rules_dt <- function(df,
                                      adherence_multiplier = 0.70,        # e.g. 0.70 (70% adherent)
                                      cap              = 30L,
                                      gap_allowed      = 183L,      # 183-day “new user” rule
                                      earliest_index_date = "2009-07-02",
                                      age_criteria     = 18L,
                                      use_grace = TRUE) {

  dt <- as.data.table(df)

  # ---- Types ----
  if (!inherits(dt$SVCDATE, "IDate")) dt[, SVCDATE := as.IDate(SVCDATE)]
  if (!is.integer(dt$DAYSUPP))        dt[, DAYSUPP := as.integer(DAYSUPP)]
  if (!"AGE" %in% names(dt))          dt[, AGE := NA_integer_]

  if (!is.integer(cap))          cap          <- as.integer(cap)
  if (!is.integer(gap_allowed))  gap_allowed  <- as.integer(gap_allowed)
  earliest_index_date <- as.IDate(earliest_index_date)

  # Sanity check for adherence
  if (is.na(adherence_multiplier) || adherence_multiplier < 0 || adherence_multiplier > 1) {
    stop("adherence_multiplier should be an adherence proportion in [0,1], e.g., 0.70")
  }

  # Make ordering deterministic
  setorder(dt, ENROLID, SVCDATE, GENNME)

  # ---- 1) drug_end_plus_grace ----
  # grace ≈ (1 - adherence) * DAYSUPP, capped by `cap`
  if (isTRUE(use_grace)) {
  dt[, grace_raw  := as.integer(round(DAYSUPP * (1 - adherence_multiplier)))]
  dt[, grace_days := pmin(grace_raw, cap)]
  dt[, grace_raw  := NULL]
  } else {
    dt[, grace_days := 0L]
  }

  dt[, drug_end_plus_grace := SVCDATE + (DAYSUPP - 1L) + grace_days]

  # ---- 2) flag_gaps_and_assign_episodes (PERSON-level) ----
  # Episodes are per ENROLID across all OACs.
  # First fill for each ENROLID is forced to start episode 0.

  setorder(dt, ENROLID, SVCDATE, GENNME)

  dt[, prev_end := shift(drug_end_plus_grace, fill = SVCDATE[1L]), by = ENROLID]
  dt[, days_since_last := as.integer(SVCDATE - prev_end)]

  dt[, gap_flag := fifelse(
    .I == .I[1L] | days_since_last > gap_allowed,  # first row or big gap
    1L,
    0L
  ), by = ENROLID]

  dt[, episode_number := cumsum(gap_flag), by = ENROLID]

  dt[, prev_end := NULL]

  # ---- 3) assign_index_date, age_at_index, index_med, oac_switch ----
  # Now episodes are well-defined at the person level.

  setorder(dt, ENROLID, episode_number, SVCDATE, GENNME)

  dt[, index_date   := SVCDATE[1L], by = .(ENROLID, episode_number)]
  dt[, age_at_index := AGE[1L],     by = .(ENROLID, episode_number)]

  # Pick index_med as drug on index_date; if multiple, use first after sort
  dt[, index_med := GENNME[1L], by = .(ENROLID, episode_number)]

  dt[, oac_switch := fifelse(GENNME == index_med, "match", "switch")]

  # ---- 4) filter for eligible episodes ----
  dt <- dt[index_date > earliest_index_date &
             !is.na(age_at_index) &
             age_at_index >= as.integer(age_criteria)]

  setorder(dt, ENROLID, episode_number, SVCDATE)
  dt[]
}

# ======================

# Base case (grace ON)
all_oac_index <- postclean_assign_rules_dt(
  cleaned_drug_data,
  adherence_multiplier = 0.70,   # 70% adherent -> grace = 30% of DAYSUPP (capped by `cap`)
  cap = 30L,
  gap_allowed = 183L,
  earliest_index_date = "2009-07-02",
  age_criteria = 18L, 
  use_grace = USE_GRACE_OBJECT
)
# 
# # Sensitivity (grace OFF)
# all_oac_index_nograce <- postclean_assign_rules_dt(
#   cleaned_drug_data,
#   adherence_multiplier = 1.0,  # value irrelevant if use_grace = FALSE
#   cap = 0L,
#   gap_allowed = 183L,
#   earliest_index_date = "2009-07-02",
#   age_criteria = 18L,
#   use_grace = FALSE
# )

# ── Exclude patients with ≥2 distinct OACs on the *index date* ────────────────
# Index date is the first OAC fill. We look only at fills on that date and count distinct OAC names.

oac_names <- c("Apixaban","Rivaroxaban","Dabigatran","Edoxaban","Warfarin")

ambiguous_ids <- all_oac_index |>
  filter(GENNME %in% oac_names, SVCDATE == index_date) |>
  group_by(ENROLID, episode_number, index_date) |>
  summarise(n_oac = n_distinct(GENNME), .groups = "drop") |>
  filter(n_oac >= 2) |>
  distinct(ENROLID) |>
  pull()

message("Excluding ", length(unique(ambiguous_ids)),
        " patients with multiple distinct OACs on their index date.")

all_oac_index <- all_oac_index |>
  filter(!ENROLID %in% ambiguous_ids)
  
# Save dataset so don't have to do that again
write_parquet(all_oac_index, file.path(proj_root, "data", "all_oac_index.parquet"))

# Open dataset
# all_oac_index <- read_parquet(file.path(proj_root, "data", "all_oac_index.parquet"))

#Extract unique IDs of OAC users meeting criteria  
all_drug_index_ids <- unique(all_oac_index$ENROLID) #2057997

```

# Continuous enrollment

```{r}

# ── IDs + index date for CE assessment ────────────────────────────────────────
cohort_ids_for_CE <- all_oac_index |>
  arrange(ENROLID, index_date) |>
  select(ENROLID, index_date) |>
  distinct() |>
  mutate(index_date = as.Date(index_date))

cont_enrollment_ids <- unique(cohort_ids_for_CE$ENROLID)

# ── Load enrollment windows (T files) only for relevant IDs ───────────────────
load_enrollment_data <- function(path, ids) {
  open_dataset(path) |>
    select(ENROLID, DTSTART, DTEND) |>
    filter(ENROLID %in% ids) |>
    collect() |>
    mutate(
      DTSTART = as.Date(DTSTART),
      DTEND   = as.Date(DTEND)
    )
}

ccae_enroll <- load_enrollment_data("//pharm-c-psop/TruvenData/Truven Data R/ccae/t", cont_enrollment_ids)
mdcr_enroll <- load_enrollment_data("//pharm-c-psop/TruvenData/Truven Data R/mdcr/t", cont_enrollment_ids)
all_enroll  <- bind_rows(ccae_enroll, mdcr_enroll)

# ── Continuous enrollment filter (183d lookback, 0d after, 30d max gap) ───────
continuous_enrollment_result <- ContinuousEnrollment(
  enrollment_data = all_enroll,
  data            = cohort_ids_for_CE,
  days_after      = 0,
  days_before     = 183,
  max_gap         = 30,
  index_date_var  = index_date
)

# ── Vector of IDs with CE ─────────────────────────────────────────────────────
ids_with_ce <- unique(continuous_enrollment_result$ENROLID)
message("CE-kept IDs: ", length(ids_with_ce))

write_parquet(continuous_enrollment_result, file.path(proj_root, "data", "continuous_enrollment_result.parquet")) 
```

#Chunk to evaluate stop of follow-up (disenrollment)

```{r}
# Create parquet file of T datasets with relevant IDs
all_enroll |> write_parquet(file.path(proj_root, "data", "enrollment_parquet.parquet")) 

# Read parquet file back into the environment
enrollment_parquet <- read_parquet(file.path(proj_root, "data", "enrollment_parquet.parquet")) 

max_gap <- 30

# Filter for ids with CE determined above
disenrollment <- enrollment_parquet |>
  filter(ENROLID %in% ids_with_ce) |> 
  select(ENROLID, DTSTART, DTEND) |> 
  to_duckdb() |>
  window_order(ENROLID, DTSTART) |>  
  group_by(ENROLID) |> 
  mutate(
    gap_days = as.numeric(DTSTART - lag(DTEND) - 1),      # true gap = start - prev_end - 1
    gap_days = if_else(is.na(gap_days), max_gap + 1, pmax(gap_days,0)), # treat first row as big gap
    continuous_cov_start = if_else(gap_days > max_gap, DTSTART, NA),
    cont_enrol = if_else(is.na(continuous_cov_start), 0, 1),
    episode = cumsum(cont_enrol)
  ) |>  
  ungroup() |> 
  group_by(ENROLID, episode) |> 
  summarise(
    start_cont_enrol = min(DTSTART), 
    end_cont_enrol   = max(DTEND),
    .groups = "drop"
  ) |> 
  collect()

b <- cohort_ids_for_CE |> 
  filter(ENROLID %in% ids_with_ce) |> 
  left_join(disenrollment, by = "ENROLID") |> 
  mutate(index_date = as.Date(index_date), 
         ENROLID    = as.character(ENROLID)) |> 
  arrange(ENROLID, index_date) |>
  filter(start_cont_enrol <= index_date, end_cont_enrol >= index_date) |> 
  select(ENROLID, index_date, end_cont_enrol)

all_oac_index_ce <- all_oac_index |> 
  filter(ENROLID %in% ids_with_ce) |>
  mutate(
    ENROLID    = as.character(ENROLID),
    index_date = as.Date(index_date) ) |> 
  left_join(b, by = c("ENROLID", "index_date"))

# Save dataset so you don't have to recompute
write_parquet(all_oac_index_ce, file.path(proj_root, "data", "all_oac_index_ce.parquet"))

# Reopen if needed
all_oac_index_ce <- read_parquet(file.path(proj_root, "data", "all_oac_index_ce.parquet"))


```

# Apply continuous exposure rules

```{r}
# Start from your big dataset
dt <- as.data.table(all_oac_index_ce)

# Ensure dates are base Date (not IDate) to play nice with arithmetic
# (If they are already Date, this is harmless)
dt[, SVCDATE := as.Date(SVCDATE)]

# Order like arrange()
setorder(dt, ENROLID, episode_number, SVCDATE)

# By episode: set exhaustion_date + next fill
dt[, `:=`(
  exhaustion_date        = SVCDATE + DAYSUPP - 1L,          # inclusive days supply
  next_prescription_date = shift(SVCDATE, type = "lead"),   # like lead()
  next_prescription_drug = shift(GENNME, type = "lead")     # like lead()
), by = .(ENROLID, episode_number)]

# Grace days controlled by USE_GRACE_OBJECT
if (isTRUE(USE_GRACE_OBJECT)) {
  dt[, grace_days := pmin(round(DAYSUPP * 0.3), 30L)]       # 30% grace, cap at 30
} else {
  dt[, grace_days := 0L]
}

# adherence_status
dt[, adherence_status := fifelse(
  !is.na(next_prescription_date) &
    next_prescription_date <= (exhaustion_date + grace_days) &
    next_prescription_drug == index_med,
  "Adherent",
  fifelse(
    !is.na(next_prescription_date) & next_prescription_drug != index_med,
    "Switched",
    "Discontinued"
  )
)]

# end_date
dt[, end_date := fifelse(
  adherence_status == "Adherent",
  as.Date(NA_real_),                                # keep going
  fifelse(
    adherence_status == "Switched",
    next_prescription_date - 1L,                    # stop at switch
    exhaustion_date + grace_days                    # stop at gap end
  )
)]

cont_exposure <- dt[
  , .(
    discontinuation_or_switch_date = {
      x <- end_date[!is.na(end_date)]
      if (length(x) == 0L) as.Date(NA_real_) else min(x)
    }
  ),
  by = .(ENROLID, episode_number)
]

dt[, c("exhaustion_date", "grace_days",
       "next_prescription_date", "next_prescription_drug",
       "adherence_status", "end_date") := NULL]

# ---- Merge back; cap follow-up by enrollment and study end ----

# Start from your main dataset
dt_index <- as.data.table(all_oac_index_ce)
ce_dt    <- as.data.table(cont_exposure)

# Make sure key types are consistent
dt_index[, ENROLID := as.character(ENROLID)]
ce_dt[,  ENROLID := as.character(ENROLID)]

# (If needed) ensure dates are base Date
dt_index[, `:=`(
  index_date    = as.Date(index_date),
  end_cont_enrol = as.Date(end_cont_enrol)  # if it exists / is used later
)]
ce_dt[, discontinuation_or_switch_date := as.Date(discontinuation_or_switch_date)]

# Key the tables for fast join
setkey(dt_index, ENROLID, episode_number)
setkey(ce_dt,    ENROLID, episode_number)

# Fast join: bring discontinuation_or_switch_date onto dt_index
dt_index[ce_dt, discontinuation_or_switch_date := i.discontinuation_or_switch_date]

study_end <- as.Date("2021-12-31")

dt_index[, obj_period_end := {
  # Replace NA with study_end, then take min (cap at study_end)
  end_cont   <- fifelse(is.na(end_cont_enrol),           study_end, end_cont_enrol)
  disc_or_sw <- fifelse(is.na(discontinuation_or_switch_date), study_end, discontinuation_or_switch_date)
  pmin(end_cont, disc_or_sw, study_end, na.rm = TRUE)
}]

dt_index[, follow_up_days := as.integer(obj_period_end - index_date + 1L)]

# Filter follow-up > 0
dt_index <- dt_index[follow_up_days > 0]

# Distinct by selected columns
oac_cohort <- unique(
  dt_index[, .(
    ENROLID,
    episode_number,
    index_med,
    index_date,
    age_at_index,
    obj_period_end,
    follow_up_days
  )]
)

write_parquet(
  oac_cohort,
  file.path(proj_root, "data","oac_cohort.parquet")
)

# oac_cohort <- read_parquet(file.path(proj_root, "data", "oac_cohort.parquet"))

# IDs to use downstream
oac_user_ids <- unique(oac_cohort$ENROLID)


```

# Outcome Identification

\# 3. IDENTIFY BLEED EVENTS WITH FULL NUANCED RULES \# Rule 2: For definite bleed codes, PDX (principal diagnosis) must contain one of the definite codes. \# Rule 3: For "possible" bleed codes, PDX must contain a possible code and either: \# (a) at least one secondary diagnosis (DX2:DX15) contains a definite bleed code, OR \# (b) a transfusion revenue code is present. \# Rule 4: For unspecified bleed codes, PDX must be in the unspec group and require secondary definite bleed code (transfusion is NOT sufficient). \# Rule 5: For GU bleed codes, if PDX matches a GU possible code (e.g., 6262), then require that at least one secondary diagnosis contains a code from all_comb_sec.


```{r}

identify_bleed_outcome <- function(dataset_path_s, dataset_path_i, dataset_path_o, output_path_event) {
  
  
  # --- Collapse Bleed Code Vectors into Regex Strings ---
  gib_icd9_ind_pattern      <- paste(gib_icd9_ind, collapse = "|")
  gu_icd9_ind_pattern       <- paste(gu_icd9_ind, collapse = "|")
  cerebral_icd9_ind_pattern <- paste(cerebral_icd9_ind, collapse = "|")
  other_icd9_ind_pattern    <- paste(other_icd9_ind, collapse = "|")
  all_icd9_bleeds_ind_pattern <- paste(all_icd9_bleeds_ind, collapse = "|")
  
  gib_icd10_ind_pattern      <- paste(gib_icd10_ind, collapse = "|")
  gu_icd10_ind_pattern       <- paste(gu_icd10_ind, collapse = "|")
  cerebral_icd10_ind_pattern <- paste(cerebral_icd10_ind, collapse = "|")
  other_icd10_ind_pattern    <- paste(other_icd10_ind, collapse = "|")
  all_icd10_bleeds_ind_pattern <- paste(all_icd10_bleeds_ind, collapse = "|")
  
  all_gib_icd9_possible_pattern  <- paste(all_gib_icd9_possible, collapse = "|")
  all_unspec_icd9_possible_pattern <- paste(all_unspec_icd9_possible, collapse = "|")
  gu_icd9_possible_pattern         <- gu_icd9_possible  # Already a string
  
  all_gib_icd10_possible_pattern  <- paste(all_gib_icd10_possible, collapse = "|")
  all_unspec_icd10_possible_pattern <- paste(all_unspec_icd10_possible, collapse = "|")
  
  all_comb_sec_pattern_icd9  <- paste(all_comb_sec_icd9, collapse = "|")
  all_comb_sec_pattern_icd10 <- paste(all_comb_sec_icd10, collapse = "|")
  
  # (Assume trauma_hcpcs_all and trauma_check_icd9/trauma_check_icd10, etc. are defined externally)
    oac_user_ids <- as.numeric(oac_user_ids)
  # =========================================================================
  # 1. LOAD TRANSFUSION DATA 
  transfusion_data <- open_dataset(dataset_path_s) %>%
    select(ENROLID, YEAR, ADMDATE, DISDATE, REVCODE) %>%
    filter(ENROLID %in% oac_user_ids) %>%
    collect() %>%
    mutate(REVCODE3 = substr(REVCODE, 1, 3)) %>%
    filter(REVCODE3 %in% c("038","039")) %>%
    transmute(ENROLID, YEAR, ADMDATE = as.Date(ADMDATE), DISDATE = as.Date(DISDATE),
              transfusion_code = 1L) %>%
    distinct()
  
  # =========================================================================
  # 2. LOAD INPATIENT DATA & MERGE TRANSFUSION INFO
  inpatient_data <- open_dataset(dataset_path_i, unify_schemas = TRUE) %>%
    select(ENROLID, YEAR, ADMDATE, AGE, DAYS, DISDATE, DXVER, PDX, DX1:DX15, PROC1:PROC15) %>%
    filter(ENROLID %in% oac_user_ids) %>%
    collect() %>%
    left_join(transfusion_data, by = c("ENROLID", "YEAR", "ADMDATE", "DISDATE")) %>%
    mutate(PDX = coalesce(PDX, DX1)) |> 
    mutate(
      DXVER = case_when(
        DXVER %in% c("0","9") ~ as.numeric(DXVER),
        is.na(DXVER) & ADMDATE >= as.Date("2015-10-01") ~ 0,
        is.na(DXVER) & ADMDATE <  as.Date("2015-10-01") ~ 9,
        TRUE ~ suppressWarnings(as.numeric(DXVER))
    )) |> 
    filter(!is.na(DXVER)) |> 
    # Unite secondary diagnosis columns for vectorized matching.
    mutate(across(c(PDX, DX1:DX15, PROC1:PROC15), as.character))
  
  # =========================================================================
  # 3. IDENTIFY BLEED EVENTS WITH NUANCED RULES
  sec_dx_cols <- paste0("DX", 2:15)
  proc_cols <- paste0("PROC", 1:15)
  
  inpatient_bleed <- inpatient_data %>%
    mutate(
      definite_bleed = case_when(
        DXVER == 9 ~ str_detect(PDX, all_icd9_bleeds_ind_pattern),
        DXVER == 0 ~ str_detect(PDX, all_icd10_bleeds_ind_pattern),
        TRUE ~ FALSE
      ),
      possible_bleed = case_when(
        DXVER == 9 ~ ( str_detect(PDX, all_gib_icd9_possible_pattern) | 
                        str_detect(PDX, all_unspec_icd9_possible_pattern) | 
                        str_detect(PDX, gu_icd9_possible_pattern) ),
        DXVER == 0 ~ ( str_detect(PDX, all_gib_icd10_possible_pattern) | 
                        str_detect(PDX, all_unspec_icd10_possible_pattern) ),
        TRUE ~ FALSE
      ),
      
      has_sec_bleed_icd9   = if_any(all_of(sec_dx_cols), ~ str_detect(.x, all_icd9_bleeds_ind_pattern)),
      has_sec_bleed_icd10  = if_any(all_of(sec_dx_cols), ~ str_detect(.x, all_icd10_bleeds_ind_pattern)),
      has_icd9_comb        = if_any(all_of(sec_dx_cols), ~ str_detect(.x, all_comb_sec_pattern_icd9)),
      has_icd10_comb       = if_any(all_of(sec_dx_cols), ~ str_detect(.x, all_comb_sec_pattern_icd10)),
      
      confirmatory = case_when(
        DXVER == 9 & str_detect(PDX, all_unspec_icd9_possible_pattern) ~ has_sec_bleed_icd9,
        DXVER == 0 & str_detect(PDX, all_unspec_icd10_possible_pattern) ~ has_sec_bleed_icd10,
        DXVER == 9 & str_detect(PDX, gu_icd9_possible_pattern) ~ has_icd9_comb,
        DXVER == 9 ~ (has_sec_bleed_icd9  | !is.na(transfusion_code)),
        DXVER == 0 ~ (has_sec_bleed_icd10 | !is.na(transfusion_code)),
        TRUE ~ FALSE
        ),
      
      bleed_code = (definite_bleed | (possible_bleed & confirmatory)),
      
      bleed_GI    = if_else(DXVER == 9, str_detect(PDX, gib_icd9_ind_pattern),
                             if_else(DXVER == 0, str_detect(PDX, gib_icd10_ind_pattern), FALSE)),
      bleed_GU    = if_else(DXVER == 9, str_detect(PDX, gu_icd9_ind_pattern),
                             if_else(DXVER == 0, str_detect(PDX, gu_icd10_ind_pattern), FALSE)),
      bleed_CNS   = if_else(DXVER == 9, str_detect(PDX, cerebral_icd9_ind_pattern),
                             if_else(DXVER == 0, str_detect(PDX, cerebral_icd10_ind_pattern), FALSE)),
      bleed_Other = if_else(DXVER == 9, str_detect(PDX, other_icd9_ind_pattern),
                             if_else(DXVER == 0, str_detect(PDX, other_icd10_ind_pattern), FALSE))
    ) %>%
    mutate(
      bleed_site = case_when(
        bleed_GI ~ "GI",
        bleed_GU ~ "GU",
        bleed_CNS ~ "CNS",
        bleed_Other ~ "Other",
        TRUE ~ NA_character_
      )
    ) %>%
    filter(bleed_code)
  
  # =========================================================================
  # 4. IDENTIFY TRAUMA EVENTS WITH SITE ASSIGNMENT (INPATIENT)
  
 inpatient_trauma <- inpatient_bleed %>%
  mutate(
    # any trauma dx (principal or secondary) or trauma HCPCS in any PROC field
    has_trauma_icd9  = if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd9)),
    has_trauma_icd10 = if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd10)),
    has_trauma_hcpcs = if_any(all_of(proc_cols),            ~ str_detect(.x, trauma_hcpcs_all)),

    trauma_code = case_when(
      DXVER == 9 ~ (has_trauma_icd9  | has_trauma_hcpcs),
      DXVER == 0 ~ (has_trauma_icd10 | has_trauma_hcpcs),
      TRUE ~ FALSE
    ),

    # site assignment using the same per-field logic
    trauma_site = case_when(
      DXVER == 9 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd9_GI))    ~ "GI",
      DXVER == 9 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd9_GU))    ~ "GU",
      DXVER == 9 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd9_CNS))   ~ "CNS",
      DXVER == 9 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd9_Other)) ~ "Other",
      DXVER == 0 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd10_GI))   ~ "GI",
      DXVER == 0 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd10_GU))   ~ "GU",
      DXVER == 0 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd10_CNS))  ~ "CNS",
      DXVER == 0 & if_any(c("PDX", all_of(sec_dx_cols)), ~ str_detect(.x, trauma_check_icd10_Other))~ "Other",
      TRUE ~ NA_character_
    )
  ) %>%
  transmute(ENROLID,
              ADMDATE = as.Date(ADMDATE),
              trauma_code, trauma_site) %>%
    filter(trauma_code, !is.na(trauma_site)) %>%
    mutate(trauma_date = ADMDATE) %>%
    select(ENROLID, trauma_date, trauma_site)
  
  
  # =========================================================================
  # 5. IDENTIFY TRAUMA EVENTS WITH SITE ASSIGNMENT (OUTPATIENT)
  bleed_ids <- unique(inpatient_bleed$ENROLID)
  
  outpatient_data <- open_dataset(dataset_path_o, unify_schemas = TRUE) %>%
    select(ENROLID, SVCDATE, DXVER, DX1, DX2, DX3, DX4, PROC1) %>%
    filter(ENROLID %in% bleed_ids) %>%
    collect() %>%
    mutate(
    DXVER = case_when(
      DXVER %in% c("0","9") ~ as.numeric(DXVER),
      is.na(DXVER) & SVCDATE >= as.Date("2015-10-01") ~ 0,
      is.na(DXVER) & SVCDATE <  as.Date("2015-10-01") ~ 9,
      TRUE ~ suppressWarnings(as.numeric(DXVER))
    )
  ) %>%
  filter(!is.na(DXVER)) %>%
  mutate(across(c(DX1, DX2, DX3, DX4, PROC1), as.character))

out_dx_cols <- paste0("DX", 1:4)

outpatient_trauma <- outpatient_data %>%
  mutate(
    has_trauma_icd9  = if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd9)),
    has_trauma_icd10 = if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd10)),
    has_trauma_hcpcs = str_detect(PROC1, trauma_hcpcs_all),

    trauma_code = case_when(
      DXVER == 9 ~ (has_trauma_icd9  | has_trauma_hcpcs),
      DXVER == 0 ~ (has_trauma_icd10 | has_trauma_hcpcs),
      TRUE ~ FALSE
    ),

    trauma_site = case_when(
      DXVER == 9 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd9_GI))    ~ "GI",
      DXVER == 9 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd9_GU))    ~ "GU",
      DXVER == 9 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd9_CNS))   ~ "CNS",
      DXVER == 9 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd9_Other)) ~ "Other",
      DXVER == 0 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd10_GI))   ~ "GI",
      DXVER == 0 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd10_GU))   ~ "GU",
      DXVER == 0 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd10_CNS))  ~ "CNS",
      DXVER == 0 & if_any(all_of(out_dx_cols), ~ str_detect(.x, trauma_check_icd10_Other))~ "Other",
      TRUE ~ NA_character_
    )
  ) %>%
  transmute(ENROLID,
              trauma_date = as.Date(SVCDATE),
              trauma_code, trauma_site) %>%
    filter(trauma_code, !is.na(trauma_site))
  
  # =========================================================================
  # 6. COMBINE ALL TRAUMA EVENTS
  all_trauma_codes <- bind_rows(inpatient_trauma, outpatient_trauma) %>%
    distinct() %>%
    arrange(ENROLID, trauma_date)
  
  # =========================================================================
  # 7. MERGE TRAUMA WITH BLEED EVENTS FOR EXCLUSION
  # Exclude a bleed if a trauma event with matching site occurs within ADMDATE-1 to ADMDATE+1.
  inpatient_bleed_trauma_merged <- inpatient_bleed %>%
    mutate(ADMDATE = as.Date(ADMDATE)) %>%
  left_join(all_trauma_codes, by = "ENROLID") %>%
  mutate(
    within_window = between(trauma_date, ADMDATE - 1, ADMDATE + 1),
    trauma_match  = (!is.na(bleed_site) & bleed_site == trauma_site)
  ) %>%
  filter(within_window, trauma_match) %>%
  distinct(ENROLID, ADMDATE) %>%
  mutate(exclusion_event = 1L)
  
  # =========================================================================
  # 8. EXCLUDE TRAUMA-RELATED BLEED EVENTS AND SAVE FINAL OUTCOME
  bleed_outcome_no_trauma <- inpatient_bleed %>%
    left_join(inpatient_bleed_trauma_merged, by = c("ENROLID", "ADMDATE")) %>%
    filter(bleed_code) %>%
    filter(is.na(exclusion_event)) |> 
  select(ENROLID, ADMDATE, DISDATE, DAYS, DXVER, PDX, starts_with("DX"), starts_with("PROC"),
           bleed_site)
  
  # Persist
  write_parquet(bleed_outcome_no_trauma, output_path_event)
  invisible(bleed_outcome_no_trauma)
}

# =============================================================================
# Example calls for CCAE and MDCR datasets:
ccae_bleed_outcome_no_trauma <- identify_bleed_outcome(
  dataset_path_s = "//pharm-c-psop/TruvenData/Truven Data R/ccae/s",
  dataset_path_i = "//pharm-c-psop/TruvenData/Truven Data R/ccae/i",
  dataset_path_o = "//pharm-c-psop/TruvenData/Truven Data R/ccae/o",
  output_path_event = "C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/ccae_bleed_outcome_no_trauma.parquet"
)

mdcr_bleed_outcome_no_trauma <- identify_bleed_outcome(
  dataset_path_s = "//pharm-c-psop/TruvenData/Truven Data R/mdcr/s",
  dataset_path_i = "//pharm-c-psop/TruvenData/Truven Data R/mdcr/i",
  dataset_path_o = "//pharm-c-psop/TruvenData/Truven Data R/mdcr/o",
  output_path_event = "C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/mdcr_bleed_outcome_no_trauma.parquet"
)

# =============================================================================
# Merge outcome files and create final outcome vector:


all_outcome <- bind_rows(ccae_bleed_outcome_no_trauma, mdcr_bleed_outcome_no_trauma) %>%
  arrange(ENROLID, ADMDATE) %>%
  group_by(ENROLID) %>%
  mutate(hospnum = row_number()) %>%
  ungroup() %>%
  mutate(eventnum = row_number()) %>%
  select(ENROLID, ADMDATE, DAYS, DISDATE, hospnum, eventnum, bleed_site)

all_outcome |> write_parquet("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/all_inpatient_bleed_no_trauma.parquet")

# Read in datasets if needed
# ccae_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/ccae_bleed_outcome_no_trauma.parquet")
# mdcr_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/mdcr_bleed_outcome_no_trauma.parquet")

all_inpatient_bleed_no_trauma <- read_parquet("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/all_inpatient_bleed_no_trauma.parquet")

outcome_vec <- unique(all_inpatient_bleed_no_trauma$ENROLID)


# ============================================================
# Collapse transfers into one clinical event (≤1-day gap)
#   — If you want stricter/looser: change threshold from 1 to 0/3/7
# ============================================================
collapse_transfers <- function(all_outcome, max_gap_days = 1) {
  # minimal columns needed
  base <- all_outcome %>%
    transmute(
      ENROLID,
      admdt = as.Date(ADMDATE),
      disdt = as.Date(DISDATE),
      bleed_site
    ) %>%
    distinct() %>%
    arrange(ENROLID, admdt, disdt)

  # identify transfer chains within patient
  chained <- base %>%
    group_by(ENROLID) %>%
    mutate(
      gap_from_prev = as.integer(admdt - lag(disdt)),
      new_episode   = if_else(is.na(gap_from_prev) | gap_from_prev > max_gap_days, 1L, 0L),
      bleed_ep_id   = cumsum(new_episode)
    ) %>%
    ungroup()

  # map of original rows to collapsed episode (for auditing)
  collapse_map <- chained %>%
    group_by(ENROLID, bleed_ep_id) %>%
    arrange(admdt, disdt, .by_group = TRUE) %>%
    mutate(row_in_chain = row_number()) %>%
    ungroup() %>%
    mutate(collapsed = row_in_chain > 1L) %>%
    select(ENROLID, admdt, disdt, bleed_site, bleed_ep_id, row_in_chain, collapsed)

  # collapsed events (one row per chain)
  events_collapsed <- collapse_map %>%
    group_by(ENROLID, bleed_ep_id) %>%
    reframe(
      bleed_adm_date = min(admdt, na.rm = TRUE),
      bleed_dis_date = max(disdt, na.rm = TRUE),
      # keep the first non-missing site across a transfer chain
      bleed_site     = {
        s <- bleed_site[!is.na(bleed_site)]
        if (length(s)) s[1] else NA_character_
      }
    )

  list(events_collapsed = events_collapsed, collapse_map = collapse_map)
}

# ---- usage ----
x <- collapse_transfers(all_outcome, max_gap_days = 1)
events_collapsed <- x$events_collapsed
collapse_map     <- x$collapse_map


# Create a vector of unique ENROLIDs with an outcome:
outcome_vec <- unique(events_collapsed$ENROLID)

events_collapsed <- events_collapsed |> 
  mutate(ENROLID = as.character(ENROLID))
```

# Create analytic cohort

```{r}
analytic_cohort_oac <- oac_cohort %>%
  select(ENROLID, episode_number, index_med, index_date, age_at_index, obj_period_end) %>%
  mutate(ENROLID = as.character(ENROLID)) |> 
  inner_join(events_collapsed, by = "ENROLID") %>%
  group_by(ENROLID) |> # not grouping by episode number so that prior events for same patient who indexes twice (or more) are captured
  mutate(pre_index_event = as.integer(any(bleed_adm_date < index_date))) |> 
  ungroup() |> 
  filter(bleed_adm_date >= index_date,
         bleed_adm_date <= obj_period_end) %>%
  arrange(ENROLID, episode_number, bleed_adm_date) %>%
  group_by(ENROLID, episode_number) %>%
  mutate(
    episode_event_seq = row_number(),
    days_from_index   = as.integer(bleed_adm_date - index_date)
  ) %>%
  ungroup() |> 
  arrange(ENROLID, index_date, bleed_adm_date) |> 
  mutate(
    day_obs_start = 0L, 
    day_obs_end = as.integer(obj_period_end - index_date), 
    day_of_event = as.integer(bleed_adm_date - index_date), 
    object = index_med
  ) 

analytic_cohort_oac <- analytic_cohort_oac |>
  mutate(object = canon_drug(object))

cohort_ids <- unique(analytic_cohort_oac$ENROLID)

write_rds(analytic_cohort_oac, "C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/analytic_cohort_oac.rds")

analytic_cohort_oac <- read_rds("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/data/analytic_cohort_oac.rds")

```

# Generate outcome datasets for each object drug

```{r}
# Generate outcome datasets for each object -------------------------------

create_oac_dataset_for_loop_outcome <- function(oac) {
    target <- canon_drug(oac)
  analytic_cohort_oac_filtered <- analytic_cohort_oac %>%
    mutate(object = canon_drug(object)) %>%
    filter(object == target)

  if (nrow(analytic_cohort_oac_filtered) == 0L) {
    message("No rows for object matching pattern: ", oac)
    return(tibble(ENROLID = integer(), episode_number = integer()))
  }
  
    # one row per ENROLID-episode with episode-level metadata
  dataset_for_loop <- analytic_cohort_oac_filtered %>%
    arrange(ENROLID, episode_number, index_date, bleed_adm_date) %>%             # deterministic
    distinct(ENROLID, episode_number, .keep_all = TRUE) %>%               # keep first per episode
    select(
      ENROLID, index_date, obj_period_end,
      day_obs_start, day_obs_end,
      object, episode_number, pre_index_event
    )


  # event-day layout (wide), one row per ENROLID-episode
  dataset_for_loop_outcome <- analytic_cohort_oac_filtered %>%
    arrange(ENROLID, episode_number, day_of_event, bleed_adm_date) %>%
    mutate(
      day_of_event = as.integer(day_of_event),
      event_number = as.integer(episode_event_seq)
    ) %>%
    select(ENROLID, episode_number, event_number, day_of_event) %>%
    distinct() %>%
    pivot_wider(
      id_cols    = c(ENROLID, episode_number),
      names_from = event_number,
      values_from = day_of_event,
      names_prefix = "event_"
    )
  
  list(
    dataset_for_loop = dataset_for_loop, 
    dataset_for_loop_outcome = dataset_for_loop_outcome
  )
}

# If your analytic_cohort_oac_2$object still uses long names, call with these:
outcome_loops_apixaban    <- create_oac_dataset_for_loop_outcome("Apixaban")
outcome_loops_rivaroxaban <- create_oac_dataset_for_loop_outcome("Rivaroxaban")
outcome_loops_dabigatran  <- create_oac_dataset_for_loop_outcome("Dabigatran")
outcome_loops_warfarin    <- create_oac_dataset_for_loop_outcome("Warfarin")

# Pull each cohort from the lists
dataset_for_loop_apixaban           <- outcome_loops_apixaban$dataset_for_loop
dataset_for_loop_rivaroxaban        <- outcome_loops_rivaroxaban$dataset_for_loop
dataset_for_loop_dabigatran         <- outcome_loops_dabigatran$dataset_for_loop
dataset_for_loop_warfarin           <- outcome_loops_warfarin$dataset_for_loop

dataset_for_loop_outcome_apixaban   <- outcome_loops_apixaban$dataset_for_loop_outcome
dataset_for_loop_outcome_rivaroxaban<- outcome_loops_rivaroxaban$dataset_for_loop_outcome
dataset_for_loop_outcome_dabigatran <- outcome_loops_dabigatran$dataset_for_loop_outcome
dataset_for_loop_outcome_warfarin   <- outcome_loops_warfarin$dataset_for_loop_outcome

```

# Get full concomitant drug data for each object

```{r}

# Use drug extraction function to get names of full drug fills for cohort
ccaed_2009_2021_full <- extract_drug_name_data(
  dataset_path = "//pharm-c-psop/TruvenData/Truven Data R/ccae/d", 
  output_path = NULL, 
  enrolid_filter = cohort_ids, 
  ndc_filter = NULL
)
mdcrd_2009_2021_full <- extract_drug_name_data(
  dataset_path = "//pharm-c-psop/TruvenData/Truven Data R/mdcr/d", 
  output_path = NULL,
  enrolid_filter = cohort_ids,
  ndc_filter = NULL
)

all_drug_full <- bind_rows(ccaed_2009_2021_full, mdcrd_2009_2021_full) 


#############

# Helper: safe grace-days and end date (inclusive)
compute_daysupp <- function(svcdate, daysupp, use_grace = TRUE, grace_mult = 0.3, cap = 30L) {
  daysupp <- coalesce(as.integer(daysupp), 0L)
  if (isTRUE(use_grace)) {
  grace   <- as.integer(round(pmin(daysupp * grace_mult, cap)))
  } else{
    grace <- 0L
  }
  # inclusive supply: + daysupp - 1, then add grace
  as.Date(svcdate) + (daysupp - 1L + grace)
}


# Define function to collect this for each OAC
oac_precipitant_processing <- function(oac){

  # Canonicalize the requested OAC up front
  target <- canon_drug(oac)

  # 1) Select object drug to analyze
  precipitant_cohort <- analytic_cohort_oac |>
    mutate(object = canon_drug(object)) |>
    filter(object == target) |>
    arrange(ENROLID, index_date) |>
    distinct(ENROLID, index_date, .keep_all = TRUE) |>
    select(ENROLID, object, index_date, obj_period_end, day_obs_start, day_obs_end, episode_number)

  # 2) Pare down all_drug_full for only ids above
  oac_specific_precipitants <- all_drug_full |>
    filter(ENROLID %in% precipitant_cohort$ENROLID) |>
    filter(!is.na(GENNME), GENNME != "")

  # 3) Join and limit to drugs used during the object window
  #    Build a case-insensitive pattern for all DOACs to exclude them:
  oac_re <- paste0("(?i)\\b(", paste(oac_drug_list, collapse = "|"), ")\\b")

  precipitant_cohort_2 <- precipitant_cohort |>
    left_join(oac_specific_precipitants, by = "ENROLID") |>
    arrange(ENROLID, SVCDATE) |>
    mutate(
      precip_start = SVCDATE,
      precip_end   = compute_daysupp(SVCDATE, DAYSUPP, use_grace = USE_GRACE_PRECIP, grace_mult = 0.3, cap = 30L)
    ) |>
    filter(precip_start <= obj_period_end & precip_end >= index_date) |>
    mutate(doac = str_detect(GENNME, oac_re)) |>
    filter(doac == FALSE) |>
    select(-doac)

  # 4) Exclusions (guard against NAs)
  precipitant_cohort_3 <- precipitant_cohort_2 |>
    mutate(
      MASTFRM  = if_else(is.na(MASTFRM),  "", MASTFRM),
      THRDTDS  = if_else(is.na(THRDTDS),  "", THRDTDS),
      GENNME   = if_else(is.na(GENNME),   "", GENNME)
    ) |>
    filter(
      !MASTFRM %in% excluded_mastfrm,
      !THRDTDS %in% excluded_thrdtds,
      !str_detect(THRDTDS, "S/M"),
      !GENNME %in% excluded_gennme
    )

  # 5) Pull out individual drugs; split combo products
  precipitant_active_ingredients <- precipitant_cohort_3 |>
    tidyr::separate_rows(GENNME, sep = "[:/;]") |>
    mutate(GENNME = str_trim(GENNME)) |>
    filter(GENNME != "") |>
    select(ENROLID, index_date, GENNME)

  # 6) Mapping (read your curated mapping table)
  drug_mapping <- read_excel("C:/Users/kahanso2/OneDrive - University of Illinois Chicago/Documents_Backup_Microsoft/doac_ddi_new/codes/drug_mapping.xlsx")
  # Expect columns: GENNME (original), NEWNAME (clean)

  # First use mapping to standardize the simple list (for counting)
  precipitant_active_ingredient_mapped <- precipitant_active_ingredients |>
    left_join(drug_mapping, by = "GENNME") |>
    mutate(GENNME = if_else(is.na(NEWNAME), GENNME, NEWNAME)) |>
    select(-NEWNAME) |>
    filter(!GENNME %in% c("", "Pl", "Solution, Multi Ingredient", "IF", "N"))

  # 7) Keep drugs with >=5 unique ENROLIDs
  drug_counts <- precipitant_active_ingredient_mapped |>
    group_by(GENNME) |>
    summarise(unique_enrolid_count = n_distinct(ENROLID), .groups = "drop") |>
    filter(unique_enrolid_count > 4)

  precipitant_vector <- unique(drug_counts$GENNME)

  # 8) Apply mapping to the big dataset (string replace over whole strings)
  #    Keep your loop for exact word matches; works fine given free text.
  replace_drug_names_in_string <- function(drug_string, mapping) {
    for (i in seq_len(nrow(mapping))) {
      pattern <- paste0("\\b", mapping$GENNME[i], "\\b")
      drug_string <- gsub(pattern, mapping$NEWNAME[i], drug_string, ignore.case = FALSE)
    }
    drug_string
  }

  precipitant_cohort_4 <- precipitant_cohort_3 |>
    mutate(GENNME = sapply(GENNME, replace_drug_names_in_string, mapping = drug_mapping))

  # 9) Clean canceling / sequential claims (your custom funcs)
  precipitant_cohort_cleaned <- precipitant_cohort_4 |>
    clean_canceling_claims() |>
    remove_sequential_pairs() |>
    select_max_fill()

  # 10) Create exposure spans relative to index and keep overlap with obs window
  precipitant_cohort_refined <- precipitant_cohort_cleaned |>
    rename(
      expo_start_date = SVCDATE,
      expo_end_date   = precip_end,
      precipitant     = GENNME
    ) |>
    select(ENROLID, object, day_obs_start, day_obs_end, index_date, obj_period_end,
           precipitant, expo_start_date, expo_end_date, episode_number) |>
    mutate(
      day_exposure_start = as.numeric(expo_start_date - index_date),
      day_exposure_end   = as.numeric(expo_end_date   - index_date)
    ) |>
    filter(day_exposure_start <= day_obs_end, day_exposure_end >= 0) |>
    mutate(
      nsaid          = str_detect(precipitant, paste(nsaids, collapse = "|")),
      antiplatelet   = str_detect(precipitant, paste(antiplatelet, collapse = "|")),
      other_anticoag = str_detect(precipitant, paste(other_anticoag, collapse = "|")),
      ssri_snri      = str_detect(precipitant, paste(ssri_snri, collapse = "|")),
      giprotect      = str_detect(precipitant, paste(giprotect, collapse = "|"))
    ) |>
    arrange(ENROLID, day_obs_start)

  return(list(cohort = precipitant_cohort_refined, vector = precipitant_vector))
}



# Initialize a list to store the results for each OAC
oac_results <- list()

# Run the function for each OAC and store both the cohort and the vector
oac_results$apixaban <- oac_precipitant_processing("Apixaban")
oac_results$rivaroxaban <- oac_precipitant_processing("Rivaroxaban")
oac_results$dabigatran <- oac_precipitant_processing("Dabigatran")
oac_results$warfarin <- oac_precipitant_processing("Warfarin")

#Pull each cohort from the list
# Access the cohort for Apixaban
apixaban_cohort <- oac_results$apixaban$cohort
rivaroxaban_cohort <- oac_results$rivaroxaban$cohort
dabigatran_cohort <- oac_results$dabigatran$cohort
warfarin_cohort <- oac_results$warfarin$cohort

# Access the precipitant vector for each
apixaban_vector <- oac_results$apixaban$vector
rivaroxaban_vector <- oac_results$rivaroxaban$vector
dabigatran_vector <- oac_results$dabigatran$vector
warfarin_vector <- oac_results$warfarin$vector

# warfarin_vector
# write.csv(warfarin_vector, "sorted_drugs.csv", row.names = FALSE)
```

```{r}
# ===============================
# Save datasets for each OAC
# ===============================

# Apixaban
write_rds(dataset_for_loop_apixaban, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_apixaban.rds"))
write_rds(dataset_for_loop_outcome_apixaban, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_outcome_apixaban.rds"))
write_rds(apixaban_cohort, file.path(proj_root, "/data/loop_datasets/apixaban_cohort.rds"))
write_rds(apixaban_vector, file.path(proj_root, "/data/loop_datasets/apixaban_vector.rds"))

# Rivaroxaban
write_rds(dataset_for_loop_rivaroxaban, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_rivaroxaban.rds"))
write_rds(dataset_for_loop_outcome_rivaroxaban, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_outcome_rivaroxaban.rds"))
write_rds(rivaroxaban_cohort, file.path(proj_root, "/data/loop_datasets/rivaroxaban_cohort.rds"))
write_rds(rivaroxaban_vector, file.path(proj_root, "/data/loop_datasets/rivaroxaban_vector.rds"))

# Dabigatran
write_rds(dataset_for_loop_dabigatran, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_dabigatran.rds"))
write_rds(dataset_for_loop_outcome_dabigatran, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_outcome_dabigatran.rds"))
write_rds(dabigatran_cohort, file.path(proj_root, "/data/loop_datasets/dabigatran_cohort.rds"))
write_rds(dabigatran_vector, file.path(proj_root, "/data/loop_datasets/dabigatran_vector.rds"))

# Warfarin
write_rds(dataset_for_loop_warfarin, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_warfarin.rds"))
write_rds(dataset_for_loop_outcome_warfarin, file.path(proj_root, "/data/loop_datasets/dataset_for_loop_outcome_warfarin.rds"))
write_rds(warfarin_cohort, file.path(proj_root, "/data/loop_datasets/warfarin_cohort.rds"))
write_rds(warfarin_vector, file.path(proj_root, "/data/loop_datasets/warfarin_vector.rds"))


# ===============================
# Reload datasets (if needed)
# ===============================

# Apixaban
dataset_for_loop_apixaban         <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_apixaban.rds"))
dataset_for_loop_outcome_apixaban <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_outcome_apixaban.rds"))
apixaban_cohort                   <- read_rds(file.path(proj_root, "data/loop_datasets/apixaban_cohort.rds"))
apixaban_vector                   <- read_rds(file.path(proj_root, "data/loop_datasets/apixaban_vector.rds"))

# Rivaroxaban
dataset_for_loop_rivaroxaban         <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_rivaroxaban.rds"))
dataset_for_loop_outcome_rivaroxaban <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_outcome_rivaroxaban.rds"))
rivaroxaban_cohort                   <- read_rds(file.path(proj_root, "data/loop_datasets/rivaroxaban_cohort.rds"))
rivaroxaban_vector                   <- read_rds(file.path(proj_root, "data/loop_datasets/rivaroxaban_vector.rds"))

# Dabigatran
dataset_for_loop_dabigatran         <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_dabigatran.rds"))
dataset_for_loop_outcome_dabigatran <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_outcome_dabigatran.rds"))
dabigatran_cohort                   <- read_rds(file.path(proj_root, "data/loop_datasets/dabigatran_cohort.rds"))
dabigatran_vector                   <- read_rds(file.path(proj_root, "data/loop_datasets/dabigatran_vector.rds"))

# Warfarin
dataset_for_loop_warfarin         <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_warfarin.rds"))
dataset_for_loop_outcome_warfarin <- read_rds(file.path(proj_root, "data/loop_datasets/dataset_for_loop_outcome_warfarin.rds"))
warfarin_cohort                   <- read_rds(file.path(proj_root, "data/loop_datasets/warfarin_cohort.rds"))
warfarin_vector                   <- read_rds(file.path(proj_root, "data/loop_datasets/warfarin_vector.rds"))


```
# Run SCCS Loop
```{r}
### 10/24/25 Chat GPT gave this which has toggles for adjustment. no idea if it works...### unadjusted check. adjust_30 changed to true. check apap to see if same.10/25 - unadjusted toggle and adjusted toggle both work (APAP unchanged) - need to test an antiplatelet to see if unchanged since or maybe some other med...could just look to see if change from previous results to these results...can run unadjusted and save, then run adjusted and save and compare...

#10/29 - didn't do above because the estimates look reasonable. will need to shrink them and see how many hits I have remaining...17 significant shrunk results before...we will see if this changes. need to be able to save after I run the loop so I don't lose everything when my computer inevitably crashes again. Need to repeat with lisinopril as well. also, need to review loop line by line and comment out what is happening...

# ===========================
# SCCS loop — Poisson FE primary (with 30d-covariate toggle)
# ===========================
if (!requireNamespace("data.table", quietly=TRUE)) install.packages("data.table")
if (!requireNamespace("gnm", quietly=TRUE))        install.packages("gnm")
if (!requireNamespace("survival", quietly=TRUE))   install.packages("survival")
suppressPackageStartupMessages({ library(data.table); library(gnm); library(survival) })

# ------------ RUN-TIME TOGGLES ------------
ADJUST_30DAY        <- TRUE    # TRUE = add 30-day covariates built from daily class exposure flags
DROP_SAME_CLASS     <- TRUE    # If adjusting, drop same-class covariate (e.g., precipitant is an NSAID -> drop NSAID_30_OLDBIN)
USE_CLOGIT_FALLBACK <- TRUE    # If Poisson FE cannot identify, try clogit on eligible strata
USE_TEST_VECTOR     <- FALSE    # If TRUE, force all objects to use 'test_vector' below

# ------------ Sensitivity toggles ------------
ONE_EVENT_ONLY    <- FALSE  # keep only first event per (ENROLID, episode_number)
LEFT_CENSOR       <- FALSE  # drop all days before first exposed day (for this precipitant) per (ENROLID, episode_number)
RIGHT_CENSOR      <- FALSE  # drop all days after first exposure window END per (ENROLID, episode_number)


# Global knobs
match_mode      <- "broad"     # "broad" keeps APAP expansions; otherwise "substring" is typical
include_washout <- INCLUDE_WASHOUT
washout_days    <- 7L

# ------------ Helpers ------------
`%||%` <- function(a, b) { if (!is.null(a) && length(a) > 0) a else b }
regex_escape <- function(x) gsub("([][{}()+*.^$|?\\\\])", "\\\\\\1", x)
.any_grepl <- function(x, pats) {
  if (length(x) == 0L) return(logical(0))
  apply(simplify2array(lapply(pats, function(p) grepl(p, x, ignore.case = TRUE, perl = TRUE))), 1, any)
}
.wald_stats <- function(est, se) {
  z <- est / se
  p <- 2 * pnorm(abs(z), lower.tail = FALSE)
  list(z_value = z, p_value = p,
       L = exp(est - 1.96*se),
       U = exp(est + 1.96*se))
}

# Broad APAP patterns (only used when match_mode="broad")
acet_broad_patterns <- c(
  "acetaminophen","paracetamol","\\bAPAP\\b","-apap","/apap"," apap",
  "\\btylenol\\b","\\bpanadol\\b","\\bmapap\\b","ofirmev"
)

# Optional class map (only used if DROP_SAME_CLASS & ADJUST_30DAY)
class_of <- function(drug_name) {
  p <- tolower(drug_name)
  if (exists("nsaids")         && p %in% tolower(nsaids))         return("nsaid")
  if (exists("antiplatelet")   && p %in% tolower(antiplatelet))   return("antiplatelet")
  if (exists("other_anticoag") && p %in% tolower(other_anticoag)) return("other_anticoag")
  if (exists("ssri_snri")      && p %in% tolower(ssri_snri))      return("ssri_snri")
  if (exists("giprotect")      && p %in% tolower(giprotect))      return("giprotect")
  return(NA_character_)
}

# ---- Build daily class exposure flags from the refined cohort ----
# Expects object_cohort to contain: ENROLID, episode_number, day_exposure_start, day_exposure_end, and boolean flags:
#   nsaid, antiplatelet, other_anticoag, ssri_snri, giprotect
generate_covariate_data <- function(control_dt, covariate_col) {
  setDT(control_dt)
  expos <- control_dt[get(covariate_col) == TRUE &
                        !is.na(day_exposure_start) & !is.na(day_exposure_end),
                      .(ENROLID, episode_number,
                        exp_start = as.integer(day_exposure_start),
                        exp_end   = as.integer(day_exposure_end))]
  expos <- expos[exp_end >= exp_start]
  if (nrow(expos) == 0L) {
    out <- data.table(ENROLID=integer(), episode_number=integer(), day=integer(), val=integer())
    setnames(out, "val", paste0(covariate_col, "_exposed"))
    return(out[])
  }
  # Build per-day flags by episode range (wide episode window)
  days <- unique(expos[, .(ENROLID, episode_number)])
  days <- control_dt[days, on=.(ENROLID, episode_number), nomatch=0L][
    , .(day = seq.int(min(day_obs_start, na.rm=TRUE), max(day_obs_end, na.rm=TRUE))),
    by = .(ENROLID, episode_number)]
  days[, val := 0L]
  days[expos, on=.(ENROLID, episode_number, day >= exp_start, day <= exp_end), val := 1L]
  setnames(days, "val", paste0(covariate_col, "_exposed"))
  days[]
}

# 30-day covariate builders (only used if ADJUST_30DAY = TRUE)
add_30d_OLDBIN <- function(dt,
                           covs = c("nsaid","antiplatelet","other_anticoag","ssri_snri","giprotect"),
                           id_cols = c("ENROLID","episode_number")) {
  data.table::setorder(dt, ENROLID, episode_number, day)
  for (nm in covs) {
    exp_col <- paste0(nm, "_exposed")
    out_col <- paste0(nm, "_30_OLDBIN")
    if (out_col %in% names(dt)) dt[, (out_col) := NULL]
    if (!(exp_col %in% names(dt))) { dt[, (exp_col) := 0L]; }
    dt[, (out_col) := {
      x <- as.integer(get(exp_col))
      r_any <- as.integer(data.table::frollsum(x, 30, align="right", fill=0L) > 0L)
      as.integer(r_any == 1L | x == 1L)  # include "today"
    }, by = id_cols]
  }
  dt[]
}

# ------------ Build daily panel for ONE object×drug ------------
build_panel <- function(object_data, object_cohort, outcome_dataset,
                        drug_label,
                        match_mode = c("substring","exact","broad"),
                        include_washout = TRUE, washout_days = 7L) {
  match_mode <- match.arg(match_mode)

  # Base daily panel per episode
  base <- as.data.table(object_data)[
    , .(day = seq(day_obs_start, day_obs_end)),
    by = .(ENROLID, episode_number)
  ][, day := as.integer(day)]

  pd <- as.data.table(object_cohort)

  # Exposure rows by match mode
  expos <- switch(match_mode,
    exact = pd[tolower(precipitant) == tolower(drug_label)],
    substring = { pat <- regex_escape(drug_label); pd[grepl(pat, precipitant, ignore.case=TRUE, perl=TRUE)] },
    broad = {
      if (tolower(drug_label) %in% c("acetaminophen","paracetamol")) {
        pd[.any_grepl(precipitant, acet_broad_patterns)]
      } else {
        pat <- regex_escape(drug_label); pd[grepl(pat, precipitant, ignore.case=TRUE, perl=TRUE)]
      }
    }
  )

  # Mark exposed days
  expos <- expos[!is.na(day_exposure_start) & !is.na(day_exposure_end)]
  expos[, `:=`(exp_start = as.integer(day_exposure_start),
               exp_end   = as.integer(day_exposure_end))]
  expos <- expos[exp_end >= exp_start]
  base[, exposed := 0L]
  if (nrow(expos)) {
    base[expos[, .(ENROLID, episode_number, exp_start, exp_end)],
         on = .(ENROLID, episode_number, day >= exp_start, day <= exp_end),
         exposed := 1L]
  }
  
    # Pre-compute censoring endpoint from EXPOSURE INTERVALS (needed for RIGHT_CENSOR)
  censor_end_dt <- NULL
  if (isTRUE(RIGHT_CENSOR) && nrow(expos)) {
    censor_end_dt <- expos[, .(censor_end = exp_end[which.min(exp_start)]),
                           by = .(ENROLID, episode_number)]
  }


  # Events (any columns starting with "event")
  ev_cols <- grep("^event", names(outcome_dataset), value = TRUE)
  base[, event := 0L]
  if (length(ev_cols)) {
    ev_long <- melt(as.data.table(outcome_dataset),
                    id.vars = c("ENROLID","episode_number"),
                    measure.vars = ev_cols,
                    value.name = "event_day",
                    na.rm = TRUE)[, .(ENROLID, episode_number, event_day)]
    if (nrow(ev_long)) {
      ev_long[, event_day := as.integer(event_day)]
      base[ev_long, on = .(ENROLID, episode_number, day = event_day), event := 1L]
    }
  }

    # ---- Sensitivity 1: keep FIRST event only per (ENROLID, episode_number) ----
  if (isTRUE(ONE_EVENT_ONLY)) {
    first_ev <- base[event == 1L,
                     .(first_event_day = min(day)),
                     by = .(ENROLID, episode_number)]
    if (nrow(first_ev)) {
      base[first_ev, on = .(ENROLID, episode_number), first_event_day := i.first_event_day]
      base[event == 1L & day != first_event_day, event := 0L]
      base[, first_event_day := NULL]
    }
  }

  # Optional washout exclusion
  if (isTRUE(include_washout)) {
    tmp <- copy(base)
    tmp[, last_exp := fifelse(exposed == 1L, day, NA_integer_), by = .(ENROLID, episode_number)]
    tmp[, last_exp := nafill(last_exp, "locf"),                  by = .(ENROLID, episode_number)]
    tmp[, washout := as.integer(exposed == 0L & (day - last_exp) %between% c(1L, as.integer(washout_days))),
        by = .(ENROLID, episode_number)]
    tmp[is.na(washout), washout := 0L]
    base <- tmp[washout == 0L][, `:=`(last_exp = NULL, washout = NULL)]
  }

  
    # ---- Sensitivity 2: LEFT censor at first exposed day (per ENROLID, episode_number) ----
  if (isTRUE(LEFT_CENSOR)) {
    first_exp <- base[exposed == 1L,
                      .(first_exp_day = min(day)),
                      by = .(ENROLID, episode_number)]
    if (nrow(first_exp)) {
      base[first_exp, on = .(ENROLID, episode_number), first_exp_day := i.first_exp_day]
      base <- base[!is.na(first_exp_day) & day >= first_exp_day][, first_exp_day := NULL]
    } else {
      base <- base[0]  # never exposed -> will fail later anyway
    }
  }

  # ---- Sensitivity 3: RIGHT censor at end of FIRST exposure window (per ENROLID, episode_number) ----
  if (isTRUE(RIGHT_CENSOR)) {
    if (!is.null(censor_end_dt) && nrow(censor_end_dt)) {
      base[censor_end_dt, on = .(ENROLID, episode_number), censor_end := i.censor_end]
      base <- base[!is.na(censor_end) & day <= censor_end][, censor_end := NULL]
    } else {
      base <- base[0]
    }
  }

  # ---- FIXED MERGE (no i.get) ----
  cov_classes <- c("nsaid","antiplatelet","other_anticoag","ssri_snri","giprotect")
  for (cc in cov_classes) {
    col <- paste0(cc, "_exposed")
    if (!(col %in% names(base))) base[, (col) := 0L]  # initialize to 0
    cov_dt <- generate_covariate_data(pd, cc)
    if (nrow(cov_dt)) {
      # Set to 1 for matched (exposed) days; stays 0 elsewhere
      base[cov_dt, on=.(ENROLID, episode_number, day), (col) := 1L]
    }
    base[, (col) := as.integer(get(col))]  # ensure integer
  }

  base[, unique_id := factor(paste0(ENROLID, ":", episode_number))]
  base[]
}

# ------------ Fit ONE cell (Poisson FE primary; optional adjustment; clogit fallback) ------------
fit_cell <- function(object_name, object_data, object_cohort, outcome_data,
                     drug_label,
                     match_mode = c("substring","exact","broad"),
                     include_washout = TRUE, washout_days = 7L) {
  match_mode <- match.arg(match_mode)
  panel <- build_panel(object_data, object_cohort, outcome_data,
                       drug_label, match_mode, include_washout, washout_days)

  # SCCS conditioning: keep only strata with ≥1 event
  df <- panel[, has_event := any(event == 1L), by = unique_id][has_event == TRUE][]
  df[, has_event := NULL]
  if (!nrow(df)) {
    return(data.table(object=object_name, drug=drug_label,
                      Estimate=NA_real_, IRR=NA_real_, SE=NA_real_,
                      z_value=NA_real_, p_value=NA_real_,
                      Lower95=NA_real_, Upper95=NA_real_,
                      method="none", reason="no_event_strata"))
  }

  # Identifiability: require within-ID exposure variation
  df <- df[, vary := (min(exposed) == 0L & max(exposed) == 1L), by = unique_id][vary == TRUE][]
  df[, vary := NULL]
  if (!nrow(df)) {
    return(data.table(object=object_name, drug=drug_label,
                      Estimate=NA_real_, IRR=NA_real_, SE=NA_real_,
                      z_value=NA_real_, p_value=NA_real_,
                      Lower95=NA_real_, Upper95=NA_real_,
                      method="none", reason="no_within_id_exposure_variation"))
  }

  # ------- Primary: Poisson FE via gnm -------
  if (isTRUE(ADJUST_30DAY)) {
    df <- add_30d_OLDBIN(df)
    cov_pool <- c("nsaid_30_OLDBIN","antiplatelet_30_OLDBIN","other_anticoag_30_OLDBIN","ssri_snri_30_OLDBIN","giprotect_30_OLDBIN")
    present <- intersect(cov_pool, names(df))
    drop_nv <- names(which(sapply(df[, ..present], function(x) length(unique(x)) < 2)))
    keep_cov <- setdiff(present, drop_nv)
    if (isTRUE(DROP_SAME_CLASS)) {
      same <- class_of(drug_label)
      if (!is.na(same)) keep_cov <- setdiff(keep_cov, paste0(same, "_30_OLDBIN"))
    }
    rhs <- if (length(keep_cov)) paste("exposed +", paste(keep_cov, collapse=" + ")) else "exposed"
  } else {
    rhs <- "exposed"
  }

  fml <- as.formula(paste("event ~", rhs))
  fit <- tryCatch(gnm(fml, eliminate = unique_id, family = poisson(), data = df), error = function(e) e)

  extract <- function(fitobj, method_tag, reason_txt) {
    sm <- summary(fitobj)$coefficients
    if (!"exposed" %in% rownames(sm)) return(NULL)
    est <- sm["exposed","Estimate"]; se <- sm["exposed","Std. Error"]
    if (!is.finite(est) || !is.finite(se)) return(NULL)
    ws <- .wald_stats(est, se)
    data.table(object=object_name, drug=drug_label,
               Estimate=est, IRR=exp(est), SE=se,
               z_value=ws$z_value, p_value=ws$p_value,
               Lower95=ws$L, Upper95=ws$U,
               method=method_tag, reason=reason_txt)
  }

  if (!inherits(fit, "error")) {
    reason_txt <- if (rhs == "exposed") "unadjusted" else paste0("adjusted: ", sub("^exposed \\+ ", "", rhs))
    out <- extract(fit, "poisson_fe", reason_txt)
    if (!is.null(out)) return(out)
  }

  # GLM FE fallback
  if (length(unique(df$unique_id)) > 1L) {
    fml_glm <- as.formula(paste("event ~", rhs, "+ factor(unique_id)"))
    fit_glm <- tryCatch(glm(fml_glm, family = poisson(), data = df), error = function(e) e)
    if (!inherits(fit_glm, "error")) {
      reason_txt <- if (rhs == "exposed") "unadjusted" else paste0("adjusted: ", sub("^exposed \\+ ", "", rhs))
      out <- extract(fit_glm, "glm_fe_fallback", reason_txt)
      if (!is.null(out)) return(out)
    }
  }

  # Optional: clogit fallback
  if (isTRUE(USE_CLOGIT_FALLBACK)) {
    case_exp <- df[event == 1L, .(case_exposed = as.integer(any(exposed == 1L))), by = unique_id]
    ctrl_exp <- df[event == 0L, .(ctrl_has0 = any(exposed == 0L), ctrl_has1 = any(exposed == 1L)), by = unique_id]
    eli <- merge(case_exp, ctrl_exp, by = "unique_id", all.x = TRUE)
    eli[is.na(ctrl_has0), ctrl_has0 := FALSE]
    eli[is.na(ctrl_has1), ctrl_has1 := FALSE]
    eli[, eligible := (case_exposed == 1L & ctrl_has0) | (case_exposed == 0L & ctrl_has1)]
    elig_ids <- eli[eligible == TRUE, unique_id]

    if (length(elig_ids) > 0L) {
      dxc <- df[unique_id %in% elig_ids, .(event, exposed, unique_id)]
      fitc <- tryCatch(clogit(event ~ exposed + strata(unique_id), data = dxc, method = "efron"),
                       error = function(e) e)
      if (!inherits(fitc, "error")) {
        smc <- summary(fitc)$coefficients
        if ("exposed" %in% rownames(smc) && is.finite(smc["exposed","coef"]) && is.finite(smc["exposed","se(coef)"])) {
          est <- smc["exposed","coef"]; se <- smc["exposed","se(coef)"]
          ws <- .wald_stats(est, se)
          return(data.table(object=object_name, drug=drug_label,
                            Estimate=est, IRR=exp(est), SE=se,
                            z_value=ws$z_value, p_value=ws$p_value,
                            Lower95=ws$L, Upper95=ws$U,
                            method="clogit", reason="poisson_failed; clogit_fallback"))
        }
      }
    }
  }

  data.table(object=object_name, drug=drug_label,
             Estimate=NA_real_, IRR=NA_real_, SE=NA_real_,
             z_value=NA_real_, p_value=NA_real_,
             Lower95=NA_real_, Upper95=NA_real_,
             method="none", reason="all_engines_failed")
}

# ------------ Driver over all objects ------------
# Expect: dataset_for_loop_*, *_cohort (precipitant_cohort_refined), *_outcome, and *_vector present
objs <- list(
  list(name="Apixaban",    data=dataset_for_loop_apixaban,    cohort=apixaban_cohort,    outcome=dataset_for_loop_outcome_apixaban,    vector=if (USE_TEST_VECTOR) test_vector else apixaban_vector),
  list(name="Rivaroxaban", data=dataset_for_loop_rivaroxaban, cohort=rivaroxaban_cohort, outcome=dataset_for_loop_outcome_rivaroxaban, vector=if (USE_TEST_VECTOR) test_vector else rivaroxaban_vector),
  list(name="Dabigatran",  data=dataset_for_loop_dabigatran,  cohort=dabigatran_cohort,  outcome=dataset_for_loop_outcome_dabigatran,  vector=if (USE_TEST_VECTOR) test_vector else dabigatran_vector),
  list(name="Warfarin",    data=dataset_for_loop_warfarin,    cohort=warfarin_cohort,    outcome=dataset_for_loop_outcome_warfarin,   vector=if (USE_TEST_VECTOR) test_vector else warfarin_vector)
)

run_scan <- function(objs, match_mode="broad", include_washout=TRUE, washout_days=7L) {
  out <- rbindlist(lapply(objs, function(o) {
    v <- o$vector %||% character(0)
    v <- as.character(v); v <- v[!is.na(v) & nzchar(v)]
    if (!length(v)) return(data.table())
    rbindlist(lapply(v, function(drug) {
      message("Processing ", o$name, " | ", drug)
      fit_cell(o$name, o$data, o$cohort, o$outcome,
               drug, match_mode, include_washout, washout_days)
    }), use.names=TRUE, fill=TRUE)
  }), use.names=TRUE, fill=TRUE)
  if (!nrow(out)) return(out[])
  out[, variance := SE^2]
  data.table::setorder(out, object, drug)
  out[]
}


# --- Run unadjusted ---
ADJUST_30DAY <- FALSE
res_unadj <- run_scan(objs, match_mode = match_mode, include_washout = include_washout, washout_days = washout_days)

data.table::fwrite(res_unadj, file.path(proj_root, "results/sccs_results_unadjusted.csv"))
saveRDS(res_unadj, file.path(proj_root, "results/sccs_results_unadjusted.rds"))

rm(res_unadj); gc()   # clear memory

# --- Run adjusted ---
ADJUST_30DAY <- TRUE
res_adj <- run_scan(objs, match_mode = match_mode, include_washout = include_washout, washout_days = washout_days)

data.table::fwrite(res_adj, file.path(proj_root, "results/sccs_results_adjusted.csv"))
saveRDS(res_adj, file.path(proj_root, "results/sccs_results_adjusted.rds"))

rm(res_adj); gc()

# # Example: filter to significant results without dplyr
# results_filtered <- results[!is.na(p_value) & p_value <= 0.05]
# print(results_filtered)

# Read unadjusted results
res_unadj <- readRDS(file.path(proj_root, "results/sccs_results_unadjusted.rds"))

# OR (if you prefer CSV)
# res_unadj <- data.table::fread(file.path(proj_root, "results/control/sccs_results_unadjusted.csv"))

# Read adjusted results
res_adj <- readRDS(file.path(proj_root, "results/sccs_results_adjusted.rds"))

# OR (if you prefer CSV)
# res_adj <- data.table::fread(file.path(proj_root, "results/control/sccs_results_adjusted.csv"))





# Sens 1: first event only
ONE_EVENT_ONLY <- TRUE; LEFT_CENSOR <- FALSE; RIGHT_CENSOR <- FALSE
res_1event <- run_scan(objs, match_mode, include_washout, washout_days)
saveRDS(res_1event, file.path(proj_root, "results/sccs_results_1event.rds"))

# Sens 2: left censor
ONE_EVENT_ONLY <- FALSE; LEFT_CENSOR <- TRUE; RIGHT_CENSOR <- FALSE
res_left <- run_scan(objs, match_mode, include_washout, washout_days)
saveRDS(res_left, file.path(proj_root, "results/sccs_results_leftcensor.rds"))

# Sens 3: right censor (first window end)
ONE_EVENT_ONLY <- FALSE; LEFT_CENSOR <- FALSE; RIGHT_CENSOR <- TRUE; RIGHT_CENSOR_MODE <- "first"
res_right <- run_scan(objs, match_mode, include_washout, washout_days)
saveRDS(res_right, file.path(proj_root, "results/sccs_results_rightcensor_first.rds"))

```

# Shrink Estimates - Newest (Need to check vs. below - dev 10/29/2025)

```{r}
# =========================================================
# Semi-Bayes shrinkage exactly per Zhou et al. (fixed prior)
#   - Primary prior:  Var(log RR) = 0.25  (~7-fold 95% range)
#   - Secondary:      Var(log RR) = 0.67  (~25-fold 95% range)
#   - Optional screen: >=5 exposed cases; drop if Var(beta) > 10
#   - Optional ratio vs Pravastatin using delta method
# =========================================================

if (!requireNamespace("data.table", quietly=TRUE)) install.packages("data.table")
suppressPackageStartupMessages({ library(data.table) })

# =========================================================
# Shrinkage for BOTH unadjusted and adjusted results
# Saves to file.path(proj_root, "results", "<label>_shrunk_priorXYZ.*")
# =========================================================

# ensure results dir exists
dir.create(file.path(proj_root, "results"), showWarnings = FALSE, recursive = TRUE)

# ---- helper: single shrinkage run + save for a given result table ----
run_and_save_shrinkage <- function(result_df, label, save_ratios = TRUE) {
  dt <- data.table::as.data.table(result_df)

  # keep only valid estimates
  dt <- dt[is.finite(Estimate) & is.finite(SE) & SE > 0]
  dt[, var_beta := SE^2]

  # Optional filters as in Zhou et al.
  dt <- dt[var_beta <= 10]
  if ("n_exposed_cases" %in% names(dt)) {
    dt <- dt[is.finite(n_exposed_cases) & n_exposed_cases >= 5]
  }

  # shrinker (fixed prior)
  shrink_fixed <- function(d, prior_var_log = 0.25, prior_mean_log = 0) {
    se2  <- d[["SE"]]^2
    tau2 <- prior_var_log
    mu0  <- prior_mean_log

    post_prec <- (1/tau2) + (1/se2)
    post_mean <- ((mu0/tau2) + (d[["Estimate"]]/se2)) / post_prec
    post_var  <- 1 / post_prec
    post_se   <- sqrt(post_var)

    d[, `:=`(
      prior_mean_log = mu0,
      prior_var_log  = tau2,
      shrunken_log_rr = post_mean,
      post_se_log     = post_se,
      lower_ci_log    = post_mean - 1.96*post_se,
      upper_ci_log    = post_mean + 1.96*post_se,
      shrunken_irr    = exp(post_mean),
      lower_ci        = exp(post_mean - 1.96*post_se),
      upper_ci        = exp(post_mean + 1.96*post_se),
      z_shrunk        = post_mean / post_se,
      p_shrunk        = 2*pnorm(abs(post_mean/post_se), lower.tail = FALSE),
      sig_any         = (exp(post_mean - 1.96*post_se) > 1 | exp(post_mean + 1.96*post_se) < 1)
    )]
    d[]
  }

  # apply both priors
  shrunk_025 <- shrink_fixed(data.table::copy(dt), prior_var_log = 0.25)
  shrunk_067 <- shrink_fixed(data.table::copy(dt), prior_var_log = 0.67)

  # optional ratio vs Pravastatin (uses shrunken values)
  ratio_vs_prava <- function(d) {
    if (!("Pravastatin" %in% d$object)) return(NULL)
    prava <- d[object == "Pravastatin", .(drug, log_rr_p = shrunken_log_rr, var_p = post_se_log^2)]
    out_list <- lapply(setdiff(unique(d$object), "Pravastatin"), function(obj) {
      oac <- d[object == obj, .(drug, log_rr_o = shrunken_log_rr, var_o = post_se_log^2)]
      m <- merge(oac, prava, by = "drug", all = FALSE)
      if (!nrow(m)) return(NULL)
      m[, `:=`(
        object        = obj,
        log_ratio     = log_rr_o - log_rr_p,
        var_log_ratio = var_o + var_p,
        se_log_ratio  = sqrt(var_o + var_p),
        ratio_rr      = exp(log_rr_o - log_rr_p),
        ratio_lower   = exp((log_rr_o - log_rr_p) - 1.96*sqrt(var_o + var_p)),
        ratio_upper   = exp((log_rr_o - log_rr_p) + 1.96*sqrt(var_o + var_p)),
        ratio_z       = (log_rr_o - log_rr_p) / sqrt(var_o + var_p),
        ratio_p       = 2*pnorm(abs((log_rr_o - log_rr_p)/sqrt(var_o + var_p)), lower.tail = FALSE),
        ratio_sig_any = (exp((log_rr_o - log_rr_p) - 1.96*sqrt(var_o + var_p)) > 1 |
                         exp((log_rr_o - log_rr_p) + 1.96*sqrt(var_o + var_p)) < 1)
      )][, .(object, drug, ratio_rr, ratio_lower, ratio_upper, ratio_z, ratio_p, ratio_sig_any)]
    })
    data.table::rbindlist(out_list, use.names = TRUE, fill = TRUE)
  }

  keep_cols <- c(
    "object","drug","method","reason",
    "Estimate","SE","IRR","Lower95","Upper95","p_value",
    "prior_mean_log","prior_var_log",
    "shrunken_log_rr","post_se_log",
    "shrunken_irr","lower_ci","upper_ci","z_shrunk","p_shrunk","sig_any"
  )

  save_both <- function(dt2, stem) {
    out_csv <- file.path(proj_root, "results", paste0(stem, ".csv"))
    out_rds <- file.path(proj_root, "results", paste0(stem, ".rds"))
    data.table::fwrite(dt2[, intersect(keep_cols, names(dt2)), with = FALSE], out_csv)
    saveRDS(dt2[, intersect(keep_cols, names(dt2)), with = FALSE], out_rds)
  }

  # save shrunk tables
  save_both(shrunk_025, paste0(label, "_shrunk_prior025"))
  save_both(shrunk_067, paste0(label, "_shrunk_prior067"))

  # quick counts in console
  quick_counts <- function(x) x[, .(n_all = .N, n_sig = sum(sig_any, na.rm=TRUE)), by = object][order(object)]
  cat("\n== ", label, " ==\n")
  print(quick_counts(shrunk_025))
  print(quick_counts(shrunk_067))

  # optional ratios
  if (isTRUE(save_ratios)) {
    r025 <- ratio_vs_prava(shrunk_025)
    r067 <- ratio_vs_prava(shrunk_067)
    if (!is.null(r025)) {
      data.table::fwrite(r025, file.path(proj_root, "results", paste0("ratio_vs_pravastatin_", label, "_prior025.csv")))
      saveRDS(r025,              file.path(proj_root, "results", paste0("ratio_vs_pravastatin_", label, "_prior025.rds")))
    }
    if (!is.null(r067)) {
      data.table::fwrite(r067, file.path(proj_root, "results", paste0("ratio_vs_pravastatin_", label, "_prior067.csv")))
      saveRDS(r067,              file.path(proj_root, "results", paste0("ratio_vs_pravastatin_", label, "_prior067.rds")))
    }
  }
}

# ---- run for both unadjusted and adjusted ----
if (exists("res_unadj")) run_and_save_shrinkage(res_unadj, "unadjusted", save_ratios = TRUE)
if (exists("res_adj"))   run_and_save_shrinkage(res_adj,   "adjusted",   save_ratios = TRUE)

cat("\nSemi-Bayes shrinkage complete for available datasets. Files saved under: ",
    file.path(proj_root, "results"), "\n")
```


